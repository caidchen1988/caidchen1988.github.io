<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://caidchen1988.github.io</id>
    <title>菜刀陈</title>
    <updated>2021-06-21T14:57:45.736Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://caidchen1988.github.io"/>
    <link rel="self" href="https://caidchen1988.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://caidchen1988.github.io/images/avatar.png</logo>
    <icon>https://caidchen1988.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 菜刀陈</rights>
    <entry>
        <title type="html"><![CDATA[Mysql高并发下优化设计——索引数据结构]]></title>
        <id>https://caidchen1988.github.io/post/mysql-gao-bing-fa-xia-you-hua-she-ji-suo-yin-shu-ju-jie-gou/</id>
        <link href="https://caidchen1988.github.io/post/mysql-gao-bing-fa-xia-you-hua-she-ji-suo-yin-shu-ju-jie-gou/">
        </link>
        <updated>2021-06-18T01:26:04.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>一般提升查询效率的最直接有效的办法就是优化索引，那么如何优化索引才能提升查询效率呢，我们就需要了解底层结构，工作原理。</p>
<h2 id="数据结构">数据结构</h2>
<p>我们知道索引和实际的数据都是存储在磁盘中（前提：存储引擎是innodb、myISAM等），在进行数据读取的时候回优先把索引加载到内存中。</p>
<p>我们的索引存储在磁盘中，索引优化从根上来说就是解决磁盘IO问题，那么怎么解决呢，从2方面处理，第一方面<code>减少IO量</code>，另一方面<code>减少IO次数</code>。</p>
<p><strong>磁盘预读</strong></p>
<p>内存跟磁盘进行交互的时候最小的逻辑单位，这个单位称为页（datapage），一般是4K或8K，由操作系统决定，我们在进行数据读取的时候，一般回读取页的整数倍，也就是4K，8K，16K，innodb存储引擎在进行数据加载的时候读取的是16K数据。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>一般提升查询效率的最直接有效的办法就是优化索引，那么如何优化索引才能提升查询效率呢，我们就需要了解底层结构，工作原理。</p>
<h2 id="数据结构">数据结构</h2>
<p>我们知道索引和实际的数据都是存储在磁盘中（前提：存储引擎是innodb、myISAM等），在进行数据读取的时候回优先把索引加载到内存中。</p>
<p>我们的索引存储在磁盘中，索引优化从根上来说就是解决磁盘IO问题，那么怎么解决呢，从2方面处理，第一方面<code>减少IO量</code>，另一方面<code>减少IO次数</code>。</p>
<p><strong>磁盘预读</strong></p>
<p>内存跟磁盘进行交互的时候最小的逻辑单位，这个单位称为页（datapage），一般是4K或8K，由操作系统决定，我们在进行数据读取的时候，一般回读取页的整数倍，也就是4K，8K，16K，innodb存储引擎在进行数据加载的时候读取的是16K数据。</p>
<!-- more -->
<p>我们知道mysql5.x之后默认存储引擎是innodb，索引数据是以B+树的方式存储的，那么思考下为什么是B+树？</p>
<p>那么我们分析下还有那些数据结构可以用于索引呢，具体如下：</p>
<p><strong>Hash表</strong></p>
<p>散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表。</p>
<p>假设：有一本中文词典，里面包含了所有的汉字，但是这些汉字是按任意顺序随意排版的，那么想要在其中找到某一个汉字，你就需要从头至尾一个一个核查，如果运气差，这个汉字正好在词典的末尾，那你需要遍历整本词典才能找到你要查的汉字。</p>
<p>优化：因为汉字和拼音之间存在着一种确定的关系，为了提高查找速度，现在将所有汉字按照拼音（key）进行排序（拼音可以根据首字母，第二个字母依次进一步排序），并且每个拼音都有一个对应页码（index），从该页开始，存放拼音对应的汉字（value）。所以找到拼音，也就能在对应的页码找到对应的汉字。其中，拼音和页码之间，有着某种固定的映射关系，可以通过某种方式计算出来（hash function）。</p>
<p>缺点：放在同一页码（具有相同拼音）的汉字可能不止一个（同音字），这时候通过拼音（key）获取到的汉字（value）应该是哪个呢？这就出现了碰撞（hash collision）。</p>
<p>总结：散列表的好处是散列查询单条数据比较快，但是坏处也比较多，会导致hash碰撞，hash冲突，导致数据散列不均匀，当需要进行范围查找的时候需要挨个便利，效率比较低。<br>
<img src="https://caidchen1988.github.io/post-images/1623987119977.png" alt="" loading="lazy"></p>
<p><strong>二叉树</strong></p>
<p>有且仅有2个节点，并且是有序的，<br>
缺点：当需要向这些数据插入更多数据的时候，会导致当前树变的非常深，增加读取次数，之前我们也说过，要提升查询效率要解决的就是IO问题，所以不适合作为索引的数据结构。<br>
<img src="https://caidchen1988.github.io/post-images/1623987019491.jpeg" alt="" loading="lazy"></p>
<p><strong>B 树</strong><br>
B树是二叉树的升级版，又叫平衡多路查找树。它和平衡二叉树的区别在于：</p>
<ol>
<li>平衡二叉树最多两个子树，而 B 树每个节点都可以有多个子树，M 阶 B 树表示每个节点最多有M个子树。</li>
<li>平衡二叉树每个节点只有一个数据和两个指向孩子的指针，而 B 树每个中间节点有 k-1 个关键字（可以理解为数据）和 k 个子树（ k 介于阶数 M 和 M/2 之间，M/2 向上取整）。</li>
<li>所有叶子节点均在同一层、叶子节点除了包含关键字和关键字记录的指针外也有指向其子节点的指针，只不过其指针地址都为 null 。<br>
<img src="https://caidchen1988.github.io/post-images/1623987652624.png" alt="" loading="lazy"></li>
</ol>
<p><strong>问题：3层B树可以存多少数据？</strong><br>
假设1条数据1KB，我们知道innoDB存储引擎中1页可以存放16KB的数据，大概可以存放16条数据，所以3层B树大概可以存储16<em>16</em>16=4096条数据。<br>
那么如果想存储更多数据怎么办，目前看只能加层数，多加1层数据，那么增加了IO次数，降低了效率。</p>
<p><strong>B+ 树</strong><br>
B+树是在B树的基础上演化而来的，我们就说不同点，只有叶子节点才有data域，叶子节点包含所有的数据，叶子节点通过指针链接形成双向链表。<br>
<img src="https://caidchen1988.github.io/post-images/1623989197922.png" alt="" loading="lazy"></p>
<p><strong>问题：3层B+树可以存多少数据？</strong><br>
同样假设1条数据1KB，主键id为bigint类型，长度8字节，指针大小设置为6字节，那么一页可以存储16384/14=1170，也就是说1页可以存储1170个指针，那么高度为3层的数据结构可以存放1170<em>1170</em>16=21902400条记录。</p>
<p><strong>问题：选择索引时候，选择int还是varchar?</strong></p>
<p>从上可知我们建立索引的时候索引指针占用的空间尽可能的少，因为int占用4个字节，所以这个问题需要看varchar是占用几个字节来判断，如果varchar(3)就选择varchar，varchar(5)就选择int。</p>
<p><strong>问题：表中的有个字段是一个varchar(100)类型的，那么最优的方式去创建索引呢？</strong></p>
<p>这个时候我们就需要用到前缀索引来帮助我们尽可能少的占用空间，具体怎么截取前缀呢。<br>
假设我们有一张表citydemo, 给city创建前缀索引，统计下重复数据出现次数，如图：<br>
<img src="https://caidchen1988.github.io/post-images/1623990350563.png" alt="" loading="lazy"></p>
<p>那么我们就截取前3位看下重复数据的次数，如图：<br>
<img src="https://caidchen1988.github.io/post-images/1623990464681.png" alt="" loading="lazy"></p>
<p>循环往复提高截取的位数，通过重复次数和原始统计出得重复次数是否相近来判断是否最优。<br>
<img src="https://caidchen1988.github.io/post-images/1623990619055.png" alt="" loading="lazy"></p>
<p>最后创建索引：</p>
<pre><code>alter table citydemo add key(city(7));
</code></pre>
<h2 id="聚簇索引">聚簇索引</h2>
<p>数据和索引存储在一起就叫聚簇索引，没有存储在一起叫做非聚簇索引。</p>
<p>innodb存储引擎在进行数据插入的时候，数据必须要跟某一个索引列存储在一起，这个索引可以是主键，如果没有主键，选择唯一键，如果没有唯一建，选择6字节的rowid来进行存储。</p>
<p>数据必定是跟某一个索引绑定在一起的，绑定数据的索引就叫做聚簇索引，其他索引的叶子结点中存储的数据不再是整行的记录，而是聚簇索引的id值。</p>
<pre><code>例如：
id,name,age,gender
id主键，name普通索引，id是聚簇索引，name对应的索引的B+树上的叶子节点存储的就是id值
</code></pre>
<h1 id="回表">回表</h1>
<p>什么是回表</p>
<h1 id="索引覆盖">索引覆盖</h1>
<h1 id="最左匹配原则">最左匹配原则</h1>
<h1 id="索引下推">索引下推</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql高并发下优化设计——执行计划]]></title>
        <id>https://caidchen1988.github.io/post/mysql-gao-bing-fa-xia-you-hua-she-ji-yi/</id>
        <link href="https://caidchen1988.github.io/post/mysql-gao-bing-fa-xia-you-hua-she-ji-yi/">
        </link>
        <updated>2021-06-17T01:49:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>在实际数据库项目开发中，由于我们不知道实际查询时数据库里发生了什么，也不知道数据库是如何扫描表、如何使用索引的，因此，我们能感知到的就只有SQL语句的执行时间。尤其在数据规模比较大的场景下，如何写查询、优化查询、如何使用索引就显得很重要了。</p>
<p>从整个Mysql查询过程中，可以对大家优化查询有一定的帮助，如图：<br>
<img src="https://caidchen1988.github.io/post-images/1623895168430.jpg" alt="" loading="lazy"></p>
<p>MySQL查询过程如下：<br>
1.客户端将查询发送到MySQL服务器；<br>
2.服务器先检查查询缓存，如果命中，立即返回缓存中的结果；否则进入下一阶段；<br>
3.服务器对SQL进行解析、预处理，再由优化器生成对象的执行计划；<br>
4.MySQL根据优化器生成的执行计划，调用存储引擎API来执行查询；<br>
5.服务器将结果返回给客户端，同时缓存查询结果；</p>
<h2 id="一-执行计划">一、执行计划</h2>
<p><strong>什么是执行计划呢？</strong><br>
执行计划，就是一条SQL语句，在数据库中实际执行的时候，一步步的分别都做了什么。<br>
也就是我们用<code>EXPLAIN</code>分析一条SQL语句时展示出来的那些信息。<br>
<img src="https://caidchen1988.github.io/post-images/1623895602278.png" alt="" loading="lazy"></p>
<p><strong>执行计划中的列</strong><br>
<img src="https://caidchen1988.github.io/post-images/1623895710929.png" alt="" loading="lazy"></p>
<p>1、select_type列<br>
<img src="https://caidchen1988.github.io/post-images/1623896259743.png" alt="" loading="lazy"></p>
<p>2、type列<br>
<img src="https://caidchen1988.github.io/post-images/1623896438688.png" alt="" loading="lazy"></p>
<p>SQL查询优化中一个很重要的指标，依次从最差到最优：</p>
<pre><code>ALL &lt; index &lt; range &lt; index_subquery &lt; unique_subquery &lt; index_merge &lt; ref_or_null &lt; fulltext &lt; ref &lt;  eq_ref &lt;   const  &lt; system
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试二：Java SPI机制原理和应用]]></title>
        <id>https://caidchen1988.github.io/post/mian-shi-er-java-spi-ji-zhi-yuan-li-he-ying-yong/</id>
        <link href="https://caidchen1988.github.io/post/mian-shi-er-java-spi-ji-zhi-yuan-li-he-ying-yong/">
        </link>
        <updated>2021-06-16T02:22:49.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>首先我们了解下什么是SPI？在具体那些场景中有应用？和Dubbo中的SPI有什么区别？</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>首先我们了解下什么是SPI？在具体那些场景中有应用？和Dubbo中的SPI有什么区别？</p>
<!-- more -->
<h2 id="一-什么是spi">一、什么是SPI？</h2>
<p>SPI 的全称为(Service Provider Interface)，是JDK内置的一种服务提供发现机制。</p>
<p>可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，不同厂商可以针对同一接口做出不同的实现，MySQL、PostgreSQL和Oracle都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。</p>
<p>Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是<strong>解耦</strong>。<br>
<img src="https://caidchen1988.github.io/post-images/1623811257757.jpeg" alt="" loading="lazy"></p>
<h2 id="二-在具体那些场景中有应用">二、在具体那些场景中有应用？</h2>
<p>那么如何才能实现Java SPI呢，分如下几步：</p>
<ul>
<li>提供接口实现</li>
<li>在classpath下的<code>META-INF/services/</code>目录里创建一个以服务接口命名的文件（全路径）</li>
<li>文件里面记录的是此 jar 包提供的具体实现类的全限定名</li>
</ul>
<p>让我们看下Mysql如何实现的<br>
<img src="https://caidchen1988.github.io/post-images/1623822165857.png" alt="" loading="lazy"></p>
<p><strong>示例</strong></p>
<p>定义接口</p>
<pre><code>public interface Driver {
    void getConnect();
}
</code></pre>
<p>Mysql实现</p>
<pre><code>public class MysqlDriver implements Driver {
    @Override
    public void getConnect() {
        System.out.println(&quot;Mysql驱动连接&quot;);
    }
}
</code></pre>
<p>PostgreSQL实现</p>
<pre><code>public class PostgreSQL implements Driver {
    @Override
    public void getConnect() {
        System.out.println(&quot;PostgreSQL驱动连接&quot;);
    }
}
</code></pre>
<p>启动类</p>
<pre><code>public class SPIDemo {
    public static void main(String[] args) {
        ServiceLoader&lt;Driver&gt; s = ServiceLoader.load(Driver.class);
        Iterator&lt;Driver&gt; iterator = s.iterator();
        while (iterator.hasNext()) {
            Driver driver =  iterator.next();
            driver.getConnect();
        }
    }
}
</code></pre>
<p><code>META-INF/services</code>配置</p>
<pre><code>com.example.spi.MysqlDriver
com.example.spi.PostgreSQL
</code></pre>
<p>查看执行结果：</p>
<figure data-type="image" tabindex="1"><img src="https://caidchen1988.github.io/post-images/1623823252148.png" alt="" loading="lazy"></figure>
<h2 id="三-spi机制的广泛应用">三、SPI机制的广泛应用</h2>
<p><strong>1、SPI机制 - JDBC DriverManager</strong></p>
<pre><code>在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。
而JDBC4.0之后不需要用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。
</code></pre>
<p><strong>JDBC接口定义</strong><br>
首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。</p>
<p><strong>mysql实现</strong><br>
在mysql的jar包<code>mysql-connector-java-6.0.6.jar</code>中，可以找到<code>META-INF/services</code>目录，该目录下会有一个名字为<code>java.sql.Driver</code>的文件，文件内容是<code>com.mysql.cj.jdbc.Driver</code>，这里面的内容就是针对Java中定义的接口的实现。</p>
<p><strong>postgresql实现</strong><br>
同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是<code>org.postgresql.Driver</code>，这是postgresql对Java的<code>java.sql.Driver</code>的实现。</p>
<p><strong>使用方法</strong><br>
上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用<code>Class.forName(&quot;com.mysql.jdbc.Driver&quot;)</code>来加载驱动了，而是直接使用如下代码：</p>
<pre><code>String url = &quot;jdbc:xxxx://xxxx:xxxx/xxxx&quot;;
Connection conn = DriverManager.getConnection(url,username,password);
</code></pre>
<p><strong>源码实现</strong><br>
上面的代码可以直接获取数据库连接进行操作，但是跟SPI有啥关系呢？上面代码没有了加载驱动的代码，我们怎么去确定使用哪个数据库连接的驱动呢？这里就涉及到使用Java的SPI扩展机制来查找相关驱动的东西了，关于驱动的查找其实都在DriverManager中，DriverManager是Java中的实现，用来获取数据库连接，在DriverManager中有一个静态代码块如下：</p>
<pre><code>static {
    loadInitialDrivers();
    println(&quot;JDBC DriverManager initialized&quot;);
}
</code></pre>
<p>接着看loadInitialDrivers方法：<br>
<img src="https://caidchen1988.github.io/post-images/1623824540422.png" alt="" loading="lazy"></p>
<p>上面的代码主要步骤是：</p>
<ul>
<li>从系统变量中获取有关驱动的定义。</li>
<li>使用SPI来获取驱动的实现。</li>
<li>遍历使用SPI获取到的具体实现，实例化各个实现类。</li>
<li>根据第一步获取到的驱动列表来实例化具体实现类。</li>
</ul>
<!-- more -->
<p><strong>2、SPI机制 - Common-Logging</strong></p>
<pre><code>common-logging（也称Jakarta Commons Logging，缩写 JCL）是常用的日志库门面。我们看下它是怎么解耦的。
</code></pre>
<p><strong>接口定义</strong></p>
<p>日志实例是通过LogFactory的getLog(String)方法创建的：</p>
<figure data-type="image" tabindex="2"><img src="https://caidchen1988.github.io/post-images/1623824762900.png" alt="" loading="lazy"></figure>
<p><strong>LogFatory实现</strong></p>
<p>LogFatory是一个抽象类，它负责加载具体的日志实现，分析其Factory getFactory()方法：</p>
<figure data-type="image" tabindex="3"><img src="https://caidchen1988.github.io/post-images/1623824997735.png" alt="" loading="lazy"></figure>
<p>可以看出，抽象类LogFactory加载具体实现的步骤如下：</p>
<ul>
<li>从vm系统属性org.apache.commons.logging.LogFactory</li>
<li>使用SPI服务发现机制，发现org.apache.commons.logging.LogFactory的实现</li>
<li>查找classpath根目录commons-logging.properties的org.apache.commons.logging.LogFactory属性是否指定factory实现</li>
<li>使用默认factory实现，org.apache.commons.logging.impl.LogFactoryImpl</li>
</ul>
<p><strong>3、SPI机制 - 插件体系</strong></p>
<pre><code>其实最具spi思想的应该属于插件开发，我们项目中也用到的这种思想，具体说一下eclipse的插件思想。
</code></pre>
<p>Eclipse使用OSGi作为插件系统的基础，动态添加新插件和停止现有插件，以动态的方式管理组件生命周期。</p>
<p>一般来说，插件的文件结构必须在指定目录下包含以下三个文件：</p>
<ul>
<li><code>META-INF/MANIFEST.MF</code>: 项目基本配置信息，版本、名称、启动器等</li>
<li><code>build.properties</code>: 项目的编译配置信息，包括，源代码路径、输出路径</li>
<li><code>plugin.xml</code>：插件的操作配置信息，包含弹出菜单及点击菜单后对应的操作执行类等</li>
</ul>
<p>当eclipse启动时，会遍历plugins文件夹中的目录，扫描每个插件的清单文件MANIFEST.MF，并建立一个内部模型来记录它所找到的每个插件的信息，就实现了动态添加新的插件。</p>
<p>这也意味着是eclipse制定了一系列的规则，像是文件结构、类型、参数等。插件开发者遵循这些规则去开发自己的插件，eclipse并不需要知道插件具体是怎样开发的，只需要在启动的时候根据配置文件解析、加载到系统里就好了，是spi思想的一种体现。</p>
<p><strong>4、SPI机制 - Spring中SPI机制</strong></p>
<p>在springboot的自动装配过程中，最终会加载<code>META-INF/spring.factories</code>文件，而加载的过程是由SpringFactoriesLoader加载的。</p>
<p>从CLASSPATH下的每个Jar包中搜寻所有<code>META-INF/spring.factories</code>配置文件，然后将解析properties文件，找到指定名称的配置后返回。</p>
<p>需要注意的是，其实这里不仅仅是会去ClassPath路径下查找，会扫描所有路径下的Jar包，只不过这个文件只会在Classpath下的jar包中。</p>
<figure data-type="image" tabindex="4"><img src="https://caidchen1988.github.io/post-images/1623825524599.png" alt="" loading="lazy"></figure>
<h2 id="四-spi和api的区别">四、SPI和API的区别</h2>
<p><strong>SPI - “接口”位于“调用方”所在的“包”中</strong></p>
<ul>
<li>概念上更依赖调用方。</li>
<li>组织上位于调用方所在的包中。</li>
<li>实现位于独立的包中。</li>
<li>常见的例子是：插件模式的插件。</li>
</ul>
<p><strong>API - “接口”位于“实现方”所在的“包”中</strong></p>
<ul>
<li>概念上更接近实现方。</li>
<li>组织上位于实现方所在的包中。</li>
<li>实现和接口在一个包中。</li>
<li>常见的例子是：开放平台接口</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://caidchen1988.github.io/post-images/1623826032214.png" alt="" loading="lazy"></figure>
<h2 id="五-spi机制的缺陷">五、SPI机制的缺陷</h2>
<p>通过上面的解析，可以发现，我们使用SPI机制的缺陷：</p>
<ul>
<li>不能按需加载，需要遍历所有的实现，并实例化，然后在循环中才能找到我们需要的实现。如果不想用某些实现类，或者某些类实例化很耗时，它也被载入并实例化了，这就造成了浪费。</li>
<li>获取某个实现类的方式不够灵活，只能通过 Iterator 形式获取，不能根据某个参数来获取对应的实现类。</li>
<li>多个并发多线程使用 ServiceLoader 类的实例是不安全的。</li>
</ul>
<h2 id="六-和dubbo-spi区别">六、和Dubbo SPI区别？</h2>
<p>因为SPI机制中的有如上之缺陷，因此 Dubbo 就自己实现了一个 SPI，除了解决按需加载问题，增加了 IOC 和 AOP 的特性，还有个自适应扩展机制。</p>
<p>我们先来看一下 Dubbo 对配置文件目录的约定，不同于 Java SPI ，Dubbo 分为了三类目录。</p>
<ul>
<li><code>META-INF/services/</code> 目录：该目录下的 SPI 配置文件是为了用来兼容 Java SPI 。</li>
<li><code>META-INF/dubbo/</code> 目录：该目录存放用户自定义的 SPI 配置文件。</li>
<li><code>META-INF/dubbo/internal/</code> 目录：该目录存放 Dubbo 内部使用的 SPI 配置文件。</li>
</ul>
<p><strong>Dubbo SPI 简单实例</strong></p>
<p>首先在 <code>META-INF/dubbo</code> 目录下按接口全限定名建立一个文件，内容如下：</p>
<pre><code>dog=com.sunnick.animal.impl.Dog
cat=com.sunnick.animal.impl.Cat
</code></pre>
<p>然后在接口上标注<code>@SPI</code>注解，以表明它要用SPI机制</p>
<pre><code>@SPI
public interface Animal {
    void run();
}
</code></pre>
<p>接着通过下面的示例代码即可加载指定的实现类。</p>
<pre><code>public class Cat implements Animal{
    @Override
    public void run() {
        System.out.println(&quot;小猫步走起来～&quot;);
    }
}

public class Dog implements Animal {
    @Override
    public void run() {
        System.out.println(&quot;小狗飞奔～&quot;);
    }
}
</code></pre>
<p>测试方法：</p>
<pre><code>public void testDubboSPI(){
    System.out.println(&quot;======dubbo SPI======&quot;);
    ExtensionLoader&lt;Animal&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Animal.class);
    Animal cat = extensionLoader.getExtension(&quot;cat&quot;);
    cat.run();
    Animal dog = extensionLoader.getExtension(&quot;dog&quot;);
    dog.run();
}
</code></pre>
<p>测试结果如下：</p>
<pre><code>======dubbo SPI======
小猫步走起来～
小狗飞奔～</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[面试一：StringBuffer 和 StringBuilder 区别]]></title>
        <id>https://caidchen1988.github.io/post/mian-shi-yi-stringbuffer-he-stringbuilder-qu-bie/</id>
        <link href="https://caidchen1988.github.io/post/mian-shi-yi-stringbuffer-he-stringbuilder-qu-bie/">
        </link>
        <updated>2021-06-15T02:51:20.000Z</updated>
        <summary type="html"><![CDATA[<pre><code>面试官：StringBuilder和StringBuffer的区别在哪？
我：StringBuilder不是线程安全的，StringBuffer是线程安全的
面试官：那StringBuilder不安全的点在哪儿？
我：。。。
</code></pre>
<p>StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的。<br>
由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。</p>
]]></summary>
        <content type="html"><![CDATA[<pre><code>面试官：StringBuilder和StringBuffer的区别在哪？
我：StringBuilder不是线程安全的，StringBuffer是线程安全的
面试官：那StringBuilder不安全的点在哪儿？
我：。。。
</code></pre>
<p>StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的。<br>
由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。</p>
<!-- more -->
<h2 id="分析">分析</h2>
<pre><code>public class StringBuilderDemo {

    public static void main(String[] args) throws InterruptedException {
        StringBuilder stringBuilder = new StringBuilder();
        for (int i = 0; i &lt; 10; i++){
            new Thread(() -&gt; {
                for (int j = 0; j &lt; 1000; j++){
                    stringBuilder.append(&quot;a&quot;);
                }
            }).start();
        }

        Thread.sleep(100);
        System.out.println(stringBuilder.length());
    }
}
</code></pre>
<p>我们能看到这段代码创建了10个线程，每个线程循环1000次往StringBuilder对象里面append字符。正常情况下代码应该输出10000，但是实际运行会输出什么呢？</p>
<figure data-type="image" tabindex="1"><img src="https://caidchen1988.github.io/post-images/1623727151708.png" alt="" loading="lazy"></figure>
<p>我们看到输出了“9173”，小于预期的10000，并且还抛出了一个ArrayIndexOutOfBoundsException异常（异常不是必现）。</p>
<p>1、为什么输出值跟预期值不一样</p>
<p>我们先看一下StringBuilder.append()方法的实现，该方法调用父类AbstractStringBuilder的append()方法。</p>
<figure data-type="image" tabindex="2"><img src="https://caidchen1988.github.io/post-images/1623727454186.png" alt="" loading="lazy"></figure>
<p>先不管其他代码，<code>count += len;</code>就不是一个原子操作，多线程场景就会出现问题。</p>
<p>2、为什么会抛出ArrayIndexOutOfBoundsException异常。</p>
<p>我们看回AbstractStringBuilder的append()方法源码的<code>ensureCapacityInternal()</code>方法是检查StringBuilder对象的原char数组的容量能不能盛下新的字符串，如果盛不下就调用expandCapacity()方法对char数组进行扩容。<br>
<img src="https://caidchen1988.github.io/post-images/1623727737533.png" alt="" loading="lazy"></p>
<p>扩容的逻辑就是new一个新的char数组，新的char数组的容量是原来char数组的两倍再加2，再通过System.arryCopy()函数将原数组的内容复制到新数组，最后将指针指向新的char数组，问题就出在此处。</p>
<p>假设现在有两个线程同时执行了StringBuilder的append()方法，两个线程都执行完了<code>ensureCapacityInternal()</code>方法，此刻count=5。</p>
<figure data-type="image" tabindex="3"><img src="https://caidchen1988.github.io/post-images/1623727837407.png" alt="" loading="lazy"></figure>
<p>这个时候线程1的cpu时间片用完了，线程2继续执行。线程2执行完整个append()方法后count变成6了<br>
<img src="https://caidchen1988.github.io/post-images/1623727874323.png" alt="" loading="lazy"></p>
<p>线程1继续执行的时候拿到的count值就是6了，执行char数组拷贝的时候就会抛出ArrayIndexOutOfBoundsException异常。</p>
<p>3、StringBuffer用什么手段保证线程安全的？</p>
<p>打开<code>append()</code>源码发现其实就是通过同步锁<code>synchronized</code>保证了线程安全。<br>
<img src="https://caidchen1988.github.io/post-images/1623728134402.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java源码分析之线程池]]></title>
        <id>https://caidchen1988.github.io/post/java-yuan-ma-fen-xi-zhi-xian-cheng-chi/</id>
        <link href="https://caidchen1988.github.io/post/java-yuan-ma-fen-xi-zhi-xian-cheng-chi/">
        </link>
        <updated>2021-06-11T01:56:22.000Z</updated>
        <content type="html"><![CDATA[<p>首先所有的需求都是机遇业务来分析，先抛问题：<br>
如果当前线程池的活跃线程是 3 个（2 个核心线程+ 1 个非核心线程），但是它们各自的任务都执行完成了。然后我每隔 3 秒往线程池里面扔一个耗时 1 秒的任务。那么 30 秒之后，活跃线程数是多少？</p>
<p>答案：3个</p>
<h2 id="demo代码">DEMO代码</h2>
<pre><code>public class ThreadTest {

    @Test
    public void test() throws InterruptedException {

        ThreadPoolExecutor executorService = new ThreadPoolExecutor(2, 3, 30, TimeUnit.SECONDS,
                new LinkedBlockingQueue&lt;&gt;(2), new DefaultThreadFactory(&quot;test&quot;),
                new ThreadPoolExecutor.DiscardPolicy());
                
        //每隔两秒打印线程池的信息
        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(1);
        scheduledExecutorService.scheduleAtFixedRate(() -&gt; {
            System.out.println(&quot;=====================================thread-pool-info:&quot; + new Date() + &quot;=====================================&quot;);
            System.out.println(&quot;CorePoolSize:&quot; + executorService.getCorePoolSize());
            System.out.println(&quot;PoolSize:&quot; + executorService.getPoolSize());
            System.out.println(&quot;ActiveCount:&quot; + executorService.getActiveCount());
            System.out.println(&quot;KeepAliveTime:&quot; + executorService.getKeepAliveTime(TimeUnit.SECONDS));
            System.out.println(&quot;QueueSize:&quot; + executorService.getQueue().size());
        }, 0, 2, TimeUnit.SECONDS);

        try {
            //同时提交5个任务,模拟达到最大线程数
            for (int i = 0; i &lt; 5; i++) {
                executorService.execute(new Task());
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
        //休眠10秒，打印日志，观察线程池状态
        Thread.sleep(10000);

        //每隔3秒提交一个任务
        while (true) {
            Thread.sleep(3000);
            executorService.submit(new Task());
        }
    }

    static class Task implements Runnable {
        @Override
        public void run(){
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread() + &quot;-执行任务&quot;);
        }
    }
}
</code></pre>
<p>这个程序的运行结果是这样的：</p>
<figure data-type="image" tabindex="1"><img src="https://caidchen1988.github.io/post-images/1623377149984.png" alt="" loading="lazy"></figure>
<p>一共五个任务，线程池的运行情况是什么样的呢？<br>
先看标号为 1 的地方：<br>
三个线程都在执行任务，然后 2 号线程和 1 号线程率先完成了任务，接着把队列里面的两个任务拿出来执行（标号为 2 的地方）。<br>
按照程序，接下来，每隔 3 秒就有一个耗时 1 秒的任务过来。而此时线程池里面的三个活跃线程都是空闲状态。<br>
那么问题就来了：<br>
该选择哪个线程来执行这个任务呢？是随机选一个吗？</p>
<figure data-type="image" tabindex="2"><img src="https://caidchen1988.github.io/post-images/1623377310031.png" alt="" loading="lazy"></figure>
<p><strong>即在我们的案例中，虽然线程都是空闲的，但是当任务来的时候不是随机调用的，而是轮询。</strong></p>
<p>由于是轮询，每三秒执行一次，所以非核心线程的空闲时间最多也就是 9 秒，不会超过 30 秒，所以一直不会被回收。</p>
<h2 id="为什么是轮询">为什么是轮询？</h2>
<p>我们通过 Demo 验证了在上面场景中线程执行顺序为轮询，那么为什么呢？</p>
<p>先Dump下线程，日志如下：<br>
<img src="https://caidchen1988.github.io/post-images/1623377777385.jpg" alt="" loading="lazy"></p>
<p>接着根据堆栈信息，我们可以定位到这里的源码：<br>
java.util.concurrent.locks.AbstractQueuedSynchronizer.ConditionObject#awaitNanos<br>
<img src="https://caidchen1988.github.io/post-images/1623377992323.jpg" alt="" loading="lazy"></p>
<p>通过源码我们可以理解成生产者-消费者的问题，三个线程就是三个消费者，现在没有任务需要处理，它们就等着生产者生产任务，然后通知它们准备消费。<br>
可以看到 addConditionWaiter 方法其实就是在操作我们要找的那个队列，学名叫做<strong>等待队列</strong>。</p>
<p>Debug 一下，看看队列里面的情况：<br>
<img src="https://caidchen1988.github.io/post-images/1623378391518.jpg" alt="" loading="lazy"><br>
巧了嘛，这不是。顺序刚好是：</p>
<ol>
<li>Thread[test-1-3,5,main]</li>
<li>Thread[test-1-2,5,main]</li>
<li>Thread[test-1-1,5,main]</li>
</ol>
<p>消费者这边我们大概摸清楚了，接着去看看生产者。</p>
<pre><code>java.util.concurrent.ThreadPoolExecutor#execute
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://caidchen1988.github.io/post-images/1623378664579.jpg" alt="" loading="lazy"></figure>
<p>线程池是在这里把任务放到队列里面去的。</p>
<p>而这个方法里面的源码是这样的：<br>
<img src="https://caidchen1988.github.io/post-images/1623378697486.jpg" alt="" loading="lazy"></p>
<p>其中<code>signalNotEmpty()</code> 最终会走到 doSignal 方法，而该方法里面会调用 transferForSignal 方法。<br>
这个方法里面会调用 <code>LockSupport.unpark(node.thred)</code>方法，唤醒线程：</p>
<figure data-type="image" tabindex="4"><img src="https://caidchen1988.github.io/post-images/1623378754575.jpg" alt="" loading="lazy"></figure>
<p>而唤醒的顺序，就是等待队列里面的顺序：</p>
<figure data-type="image" tabindex="5"><img src="https://caidchen1988.github.io/post-images/1623378865329.jpg" alt="" loading="lazy"></figure>
<p>所以，现在你知道当一个任务来了之后，这个任务该由线程池里面的哪个线程执行，这个不是随机的，也不是随便来的，是讲究一个顺序的。</p>
<p>什么顺序呢？<br>
Condition 里面的等待队列里面的顺序。详细了解请参考：https://blog.csdn.net/bohu83/article/details/51098106</p>
<h2 id="非核心线程怎么回收">非核心线程怎么回收？</h2>
<p>还是上面的例子，假设非核心线程就空闲了超过 30 秒，那么它是怎么被回收的呢？<br>
这个也是一个比较热门的面试题。</p>
<pre><code>java.util.concurrent.ThreadPoolExecutor#getTask
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://caidchen1988.github.io/post-images/1623379762912.png" alt="" loading="lazy"></figure>
<p>当 timed 参数为 true 的时候，会执行 <code>workQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)</code>方法。</p>
<p>而 timed 什么时候为 true 呢？<br>
boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;</p>
<p>参数解说：</p>
<ul>
<li>allowCoreThreadTimeOut为true<br>
该值为true，则线程池数量最后销毁到0个。</li>
<li>allowCoreThreadTimeOut为false<br>
销毁机制：超过核心线程数时，而且（超过最大值或者timeout过），就会销毁。</li>
</ul>
<p>allowCoreThreadTimeOut 默认为 false。<br>
所以，就是看<code>wc &gt; corePoolSize</code>条件，wc 是活跃线程数。此时活跃线程数为 3 ，大于核心线程数 2。<br>
最终执行<code>ThreadPoolExecutor#processWorkerExit.remove()</code>回收线程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ消息幂等（去重）通用解决方案]]></title>
        <id>https://caidchen1988.github.io/post/rocketmq-xiao-xi-mi-deng-qu-chong-tong-yong-jie-jue-fang-an/</id>
        <link href="https://caidchen1988.github.io/post/rocketmq-xiao-xi-mi-deng-qu-chong-tong-yong-jie-jue-fang-an/">
        </link>
        <updated>2021-06-10T02:11:53.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>问题出现场景</strong></p>
]]></summary>
        <content type="html"><![CDATA[<p><strong>问题出现场景</strong></p>
<!-- more -->
<p>消息中间件是一个可靠的组件，只要我把消息成功投递到了消息中间件，消息就不会丢失，即消息肯定会至少保证消息能被消费者成功消费一次，也就是我们常说的“AT LEAST ONCE”，即消息至少会被“成功消费一遍”。</p>
<p>举个例子，一个消息M发送到了消息中间件，消息投递到了消费程序A，A接受到了消息，然后进行消费，但在消费到一半的时候程序重启了，这时候这个消息并没有标记为消费成功，这个消息还会继续投递给这个消费者，直到其消费成功了，消息中间件才会停止投递。</p>
<p>然而这种可靠的特性导致，消息可能被多次地投递。举个例子，还是刚刚这个例子，程序A接受到这个消息M并完成消费逻辑之后，正想通知消息中间件“我已经消费成功了”的时候，程序就重启了，那么对于消息中间件来说，这个消息并没有成功消费过，所以他还会继续投递。这时候对于应用程序A来说，看起来就是这个消息明明消费成功了，但是消息中间件还在重复投递。</p>
<p>基于消息的投递可靠（消息不丢）是优先级更高的，所以消息不重的任务就会转移到应用程序自我实现，这也是为什么RocketMQ的文档里强调的，消费逻辑需要自我实现幂等。背后的逻辑其实就是：不丢和不重是矛盾的（在分布式场景下），但消息重复是有解决方案的，而消息丢失是很麻烦的。</p>
<h2 id="解决方案">解决方案</h2>
<p><strong>简单的消息去重解决方案</strong></p>
<p>例如：假设我们业务的消息消费逻辑是：插入某张订单表的数据，然后更新库存：</p>
<pre><code>insert into t_order values .....

update t_inv set count = count-1 where good_id = 'good123';
</code></pre>
<p>要实现消息的幂等，我们可能会采取这样的方案：</p>
<pre><code>select * from t_order where order_no = 'order123'

if(order  != null) {
    return ; //消息重复，直接返回
}
</code></pre>
<p>这对于很多情况下，的确能起到不错的效果，但是在并发场景下，还是会有问题。</p>
<!-- more -->
<p><strong>并发重复消息</strong></p>
<p>假设这个消费的所有代码加起来需要1秒，有重复的消息在这1秒内（假设100毫秒）内到达（例如生产者快速重发，Broker重启等），那么很可能，上面去重代码里面会发现，数据依然是空的（因为上一条消息还没消费完，还没成功更新订单状态），那么就会穿透掉检查的挡板，最后导致重复的消息消费逻辑进入到非幂等安全的业务代码中，从而引发重复消费的问题（如主键冲突抛出异常、库存被重复扣减而没释放等）</p>
<p>要解决上面并发场景下的消息幂等问题，一个可取的方案是开启事务把select 改成 select for update语句，把记录进行锁定。</p>
<pre><code>select * from t_order where order_no = 'THIS_ORDER_NO' for update  //开启事务
if(order.status != null) {
    return ;//消息重复，直接返回
}
</code></pre>
<p>问题：但这样消费的逻辑会因为引入了事务包裹而导致整个消息消费可能变长，并发度下降。</p>
<!-- more -->
<p><strong>基于关系数据库事务插入消息表</strong></p>
<p>要实现消息只被消费一次（并且肯定要保证能消费一次），我们可以这样做：在这个数据库中增加一个消息消费记录表，把消息插入到这个表，并且把原来的订单更新和这个插入的动作放到同一个事务中一起提交，就能保证消息只会被消费一遍了。</p>
<ul>
<li>开启事务</li>
<li>插入消息表（处理好主键冲突的问题）</li>
<li>更新订单表（原消费逻辑）</li>
<li>提交事务</li>
</ul>
<p>说明：<br>
1、这时候如果消息消费成功并且事务提交了，那么消息表就插入成功了，这时候就算RocketMQ还没有收到消费位点的更新再次投递，也会插入消息失败而视为已经消费过，后续就直接更新消费位点了。这保证我们消费代码只会执行一次。<br>
2、如果事务提交之前服务挂了（例如重启），对于本地事务并没有执行所以订单没有更新，消息表也没插入成功；而对于RocketMQ服务端来说，消费位点也没更新，所以消息还会继续投递下来，投递下来发现这个消息插入消息表也是成功的，所以可以继续消费。这保证了消息不丢失。</p>
<p>局限性：<br>
1、消息的消费逻辑必须是依赖于关系型数据库事务。如果消费的消费过程中还涉及其他数据的修改，例如Redis这种不支持事务特性的数据源，则这些数据是不可回滚的。</p>
<p>2、数据库的数据必须是在一个库，跨库无法解决</p>
<p>注：业务上，消息表的设计不应该以消息ID作为标识，而应该以业务的业务主键作为标识更为合理，以应对生产者的重发。阿里云上的消息去重只是RocketMQ的messageId，在生产者因为某些原因手动重发（例如上游针对一个交易重复请求了）的场景下起不到去重/幂等的效果（因消息id不同）。</p>
<!-- more -->
<p><strong>更复杂的业务场景</strong></p>
<p>如上所述，这种方式的实现，实际上有很多局限性，这种局限性使得这个方案基本不具备广泛应用的价值。并且由于基于事务，可能导致锁表时间过长等性能问题。</p>
<p>例如我们以一个比较常见的一个订单申请的消息来举例，可能有以下几步（以下统称为步骤X）：</p>
<ul>
<li>检查库存（RPC）</li>
<li>锁库存（RPC）</li>
<li>开启事务，插入订单表（MySQL）</li>
<li>调用某些其他下游服务（RPC）</li>
<li>更新订单状态</li>
<li>commit 事务（MySQL）</li>
</ul>
<p>这种情况下，我们如果采取消息表+本地事务的实现方式，消息消费过程中很多子过程是不支持回滚的，也就是说就算我们加了事务，实际上这背后的操作并不是原子性的。怎么说呢，就是说有可能第一条小在经历了第二步锁库存的时候，服务重启了，这时候实际上库存是已经在另外的服务里被锁定了，这并不能被回滚。当然消息还会再次投递下来，要保证消息能至少消费一遍，换句话说，锁库存的这个RPC接口本身依旧要支持“幂等”。</p>
<p>再者，如果在这个比较耗时的长链条场景下加入事务的包裹，将大大的降低系统的并发。所以通常情况下，我们处理这种场景的消息去重的方法还是会使用一开始说的业务自己实现去重逻辑的方式，如前面加select for update，或者使用乐观锁。</p>
<!-- more -->
<p><strong>拆解消息执行过程</strong></p>
<p>其中一个思路是把上面的几步，拆解成几个不同的子消息，例如：</p>
<ul>
<li>库存系统消费A：检查库存并做锁库存，发送消息B给订单服务</li>
<li>订单系统消费消息B：插入订单表（MySQL），发送消息C给自己（下游系统）消费</li>
<li>下游系统消费消息C：处理部分逻辑，发送消息D给订单系统</li>
<li>订单系统消费消息D：更新订单状态</li>
</ul>
<p>注：上述步骤需要保证本地事务和消息是一个事务的（至少是最终一致性的），这其中涉及到分布式事务消息相关的话题，不在本文论述。</p>
<p>可以看到这样的处理方法会使得每一步的操作都比较原子，而原子则意味着是小事务，小事务则意味着使用消息表+事务的方案显得可行。</p>
<p>然而，这太复杂了！这把一个本来连续的代码逻辑割裂成多个系统多次消息交互！那还不如业务代码层面上加锁实现呢。</p>
<!-- more -->
<p><strong>更通用的解决方案</strong></p>
<p>上面消息表+本地事务的方案之所以有其局限性和并发的短板，究其根本是因为它依赖于关系型数据库的事务，且必须要把事务包裹于整个消息消费的环节。</p>
<p>如果我们能不依赖事务而实现消息的去重，那么方案就能推广到更复杂的场景例如：RPC、跨库等。</p>
<p>例如，我们依旧使用消息表，但是不依赖事务，而是针对消息表增加消费状态，是否可以解决问题呢？</p>
<figure data-type="image" tabindex="1"><img src="https://caidchen1988.github.io/post-images/1623294107695.png" alt="" loading="lazy"></figure>
<p>以上是去事务化后的消息幂等方案的流程，可以看到，此方案是无事务的，而是针对消息表本身做了状态的区分：消费中、消费完成。只有消费完成的消息才会被幂等处理掉。而对于已有消费中的消息，后面重复的消息会触发延迟消费（在RocketMQ的场景下即发送到RETRY TOPIC），之所以触发延迟消费是为了控制并发场景下，第二条消息在第一条消息没完成的过程中，去控制消息不丢（如果直接幂等，那么会丢失消息（同一个消息id的话），因为上一条消息如果没有消费完成的时候，第二条消息你已经告诉broker成功了，那么第一条消息这时候失败broker也不会重新投递了）</p>
<p>我们一开始想解决的问题是否解决了：</p>
<ul>
<li>消息已经消费成功了，第二条消息将被直接幂等处理掉（消费成功）。</li>
<li>并发场景下的消息，依旧能满足不会出现消息重复，即穿透幂等挡板的问题。</li>
<li>支持上游业务生产者重发的业务重复的消息幂等问题。</li>
</ul>
<p>关于第一个问题已经很明显已经解决了，在此就不讨论了。</p>
<p>关于第二个问题是如何解决的？主要是依靠插入消息表的这个动作做控制的，假设我们用MySQL作为消息表的存储媒介（设置消息的唯一ID为主键），那么插入的动作只有一条消息会成功，后面的消息插入会由于主键冲突而失败，走向延迟消费的分支，然后后面延迟消费的时候就会变成上面第一个场景的问题。</p>
<p>关于第三个问题，只要我们设计去重的消息键让其支持业务的主键（例如订单号、请求流水号等），而不仅仅是messageId即可。所以也不是问题。</p>
<!-- more -->
<p><strong>此方案是否有消息丢失的风险？</strong></p>
<p>会发现这里实际上是有逻辑漏洞的，问题出在上面聊到的个三问题中的第2个问题（并发场景），在并发场景下我们依赖于消息状态是做并发控制使得第2条消息重复的消息会不断延迟消费（重试）。但如果这时候第1条消息也由于一些异常原因（例如机器重启了、外部异常导致消费失败）没有成功消费成功呢？也就是说这时候延迟消费实际上每次下来看到的都是消费中的状态，最后消费就会被视为消费失败而被投递到死信Topic中（RocketMQ默认可以重复消费16次）。</p>
<p>有这种顾虑是正确的！对于此，我们解决的方法是，插入的消息表必须要带一个最长消费过期时间，例如10分钟，意思是如果一个消息处于消费中超过10分钟，就需要从消息表中删除（需要程序自行实现）。所以最后这个消息的流程会是这样的：</p>
<figure data-type="image" tabindex="2"><img src="https://caidchen1988.github.io/post-images/1623294553798.png" alt="" loading="lazy"></figure>
<!-- more -->
<p><strong>更灵活的消息表存储媒介</strong></p>
<p>我们这个方案实际上没有事务的，只需要一个存储的中心媒介，那么自然我们可以选择更灵活的存储媒介，例如Redis。使用Redis有两个好处：</p>
<ul>
<li>性能上损耗更低</li>
<li>上面我们讲到的超时时间可以直接利用Redis本身的ttl实现</li>
</ul>
<p>当然Redis存储的数据可靠性、一致性等方面是不如MySQL的，需要用户自己取舍。</p>
]]></content>
    </entry>
</feed>